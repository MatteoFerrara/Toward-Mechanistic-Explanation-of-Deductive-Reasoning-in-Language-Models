{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42bacc5",
   "metadata": {},
   "source": [
    "# **Toward Mechanistic Explanation of Deductive Reasoning in Language Models**\n",
    "\n",
    "This notebook is designed to reproduce the use of the visualization tool developed in [D. Maltoni and M. Ferrara, *\"Toward Mechanistic Explanation of Deductive Reasoning in Language Models\"*, arXiv:2510.09340, 2025](https://arxiv.org/abs/2510.09340). It relies on the following Python scripts:\n",
    "- **logic_data.py** - provides functions to create the dataset used in the experimentation.\n",
    "- **model_with_hooks.py** - contains a modified version of the nanoGPT model originally implemented by [Andrej Karpathy](https://github.com/karpathy/nanoGPT) combined with the [TransformerLens](https://github.com/TransformerLensOrg/TransformerLens), a library for mechanistic interpretability of generative language models.\n",
    "- **utility_functions.py** - provides several utility functions.\n",
    "- **EnvUtilities.py** - contains the *setup_environment* function, which properly configures the environment.\n",
    "\n",
    "The following code imports all necessary modules and functions required to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402fcb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "from logic_data import create_dics, create_dataset\n",
    "from utility_functions import load_model, generate, to_tensor_prompts, to_str_tokens, prepare_data_flows_from_attention_matrices, from_logits_to_chars, from_logits_to_top_k_chars, truncated_pseudoinverse, draw_sankey, compute_avg_attention_layer_patterns\n",
    "from EnvUtilities import setup_environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edab6e67",
   "metadata": {},
   "source": [
    "In the following code cell, you will set the model file name and the prompt to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model checkpoint\n",
    "model_file_name=f\"VarLenPos_NewLitNeg_CoT_NoUlC_DB4096_mb128_Ep150_AtL2_He1_Emb128_NoMLP_NoFlAt_se127_r8.mdl\"\n",
    "\n",
    "model_checkpoint_file_path=os.path.join(os.path.abspath(''),model_file_name)\n",
    "#---\n",
    "\n",
    "# Prompt to analyze\n",
    "prompt_str = 'C>D,A>B,B>C,E>F,D>E|A>F@'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2080d8fc",
   "metadata": {},
   "source": [
    "The code cell below creates a set of index lists that will be used to visualize only specific links between attention layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db581ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_indices=list(range(44))\n",
    "all_ouptut_token_indices=list(range(23,44))\n",
    "output_premise_token_indices=list(range(24,41,4))\n",
    "output_greater_token_indices=list(range(25,42,4))\n",
    "output_consequent_token_indices=list(range(26,43,4))\n",
    "output_comma_token_indices=list(range(27,43,4))\n",
    "output_minus_token_index=list(range(43,44))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6935c4b",
   "metadata": {},
   "source": [
    "Executing the following code cell will:\n",
    "- initialize the environment,\n",
    "- create two dictionaries for character-to-index and index-to-character mappings,\n",
    "- load the model, and\n",
    "- extract the model parameters from its configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc83a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment initialization\n",
    "env = setup_environment(use_gpu = True)\n",
    "device = env['device']\n",
    "ctx = env['ctx']\n",
    "# ---\n",
    "\n",
    "# Mapping creation between characters and indices\n",
    "_, stoi, itos = create_dics(alphabet=20)\n",
    "\n",
    "# Model loading\n",
    "model, gptconf=load_model(model_checkpoint_file_path, device)\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Model parameters\n",
    "n_layer = gptconf.n_layer\n",
    "n_head = gptconf.n_head\n",
    "n_embd = gptconf.n_embd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1452b8",
   "metadata": {},
   "source": [
    "The code cell below performs the following steps:\n",
    "- uses the model to generate an output based on the input prompt (*prompt_str*),\n",
    "- creates a new string (*str_without_last_token*) that combines the prompt and the generated output, excluding the last token,\n",
    "- converts *str_without_last_token* and the generated output into two lists of characters for visualization purposes,\n",
    "- passes *str_without_last_token* to the model to obtain all cached hooks using TransformerLens functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output from the model using the prompt example\n",
    "output = generate(model, 6,True, stoi, itos, prompt_str, device, ctx)\n",
    "print(f\"Model output: {output}\")\n",
    "\n",
    "# Prepare a string containing: prompt + generated output without the last token\n",
    "str_without_last_token=output[:-1]\n",
    "\n",
    "# Convert prompt + generated output without the last token to list of characters\n",
    "prompt_last_token_charlist=to_str_tokens(str_without_last_token,\"\")\n",
    "\n",
    "# Convert generated output to list of characters\n",
    "output_charlist=to_str_tokens(output[24:],\"\")\n",
    "\n",
    "# Run the model to get cache using TransformerLens library\n",
    "model.return_all_logits = True\n",
    "_,cache=model.run_with_cache(to_tensor_prompts(str_without_last_token, stoi, device),remove_batch_dim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a2356",
   "metadata": {},
   "source": [
    "The following code processes the attention patterns stored in the cached hooks and prepares them for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7edeb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attention layer patterns from cache\n",
    "attention_layer_patterns={}\n",
    "for i in range(n_layer):\n",
    "    key = f\"transformer.h.{i}.attn.hook_pattern\"\n",
    "    attention_layer_patterns[i]=cache[key]\n",
    "\n",
    "# Process attention matrices for visualization\n",
    "attention_matrices= [attention_layer_patterns[i].cpu().numpy() for i in range(n_layer)]\n",
    "attention_layer_sources, attention_layer_targets, attention_layer_values = prepare_data_flows_from_attention_matrices(n_layer, n_head, attention_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313f9bb",
   "metadata": {},
   "source": [
    "The cell code below selects the characters corresponding to the top-ranked and second-ranked tokens decoded from the residual stream after Layer 1. This decoding is based on the [LogitLens](https://www.alignmentforum.org/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens) approach, which applies the final LM head to the residual stream to identify tokens with the highest logit values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract residual stream after first attention layer from cache\n",
    "post_l0_emb=cache[\"hook_post_li_emb.0\"]\n",
    "\n",
    "# Get logits from residual stream after first attention layer\n",
    "post_l0_logits=model.lm_head(post_l0_emb)\n",
    "\n",
    "# Get top-k characters from logits after first attention layer\n",
    "l1_top_k_subs,_=from_logits_to_top_k_chars(post_l0_logits,itos,top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac0eb4",
   "metadata": {},
   "source": [
    "The following code cell creates a dataset of 4096 examples (2048 positives and 2048 negatives) to compute average attention patterns, which will be used to visualize token-idependent links. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset of 4096 examples\n",
    "src_data, tgt_data,_,_=create_dataset(literals=6, alphabet=20, dataset_size=4096, positive_sample_with_fixed_length=False, negative_sample_with_new_literal=True, encfunc=stoi)\n",
    "data = np.concatenate((src_data, tgt_data), axis=1)\n",
    "\n",
    "# Split dataset into negative and positive examples\n",
    "negative_data = data[data[:, -1] == 6]  # Assuming 6 is the label for positive examples\n",
    "positive_data = data[data[:, -1] == 7]  # Assuming 7 is the label for positive examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f56b65",
   "metadata": {},
   "source": [
    "In the code cell below the average attention patterns are computed and prepared for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a22de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average attention patterns for the entire dataset\n",
    "avg_attention_layer_patterns=compute_avg_attention_layer_patterns(n_head,n_layer,data,model,stoi,itos,device)\n",
    "avg_attention_layer_sources, avg_attention_layer_targets, avg_attention_layer_values = prepare_data_flows_from_attention_matrices(n_layer, n_head, avg_attention_layer_patterns)\n",
    "\n",
    "# Compute average attention patterns for positive examples\n",
    "pos_avg_attention_layer_patterns=compute_avg_attention_layer_patterns(n_head,n_layer,positive_data,model,stoi,itos,device)\n",
    "pos_avg_attention_layer_sources, pos_avg_attention_layer_targets, pos_avg_attention_layer_values = prepare_data_flows_from_attention_matrices(n_layer, n_head, pos_avg_attention_layer_patterns)\n",
    "\n",
    "# Compute average attention patterns for negative examples\n",
    "neg_avg_attention_layer_patterns=compute_avg_attention_layer_patterns(n_head,n_layer,negative_data,model,stoi,itos,device)\n",
    "neg_avg_attention_layer_sources, neg_avg_attention_layer_targets, neg_avg_attention_layer_values = prepare_data_flows_from_attention_matrices(n_layer, n_head, neg_avg_attention_layer_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f3a13",
   "metadata": {},
   "source": [
    "the following code cell applies the truncated pseudoinverse approach proposed in the paper to decode the information carried by queries, keys and values into token space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_Q=0.7  \n",
    "thr_K=0.99\n",
    "thr_V=0.7\n",
    "\n",
    "# Extract Q, K, and V projection matrices from the model\n",
    "W_Q = model.transformer.h[1].attn.c_attn.weight.split(n_embd, dim=0)[0].T\n",
    "W_K = model.transformer.h[1].attn.c_attn.weight.split(n_embd, dim=0)[1].T\n",
    "W_V = model.transformer.h[1].attn.c_attn.weight.split(n_embd, dim=0)[2].T\n",
    "\n",
    "res_stream = post_l0_emb\n",
    "res_stream = model.transformer.h[1].ln_1(res_stream)  # Layer normalization applied to residual stream\n",
    "\n",
    "# Compute truncated pseudoinverse\n",
    "W_Q_inv, n_Q = truncated_pseudoinverse(W_Q.cpu().numpy(), thr_sk=thr_Q)\n",
    "W_K_inv, n_K = truncated_pseudoinverse(W_K.cpu().numpy(), thr_sk=thr_K)\n",
    "W_V_inv, n_V = truncated_pseudoinverse(W_V.cpu().numpy(), thr_sk=thr_V)\n",
    "\n",
    "# Project residual stream onto Q, K, V subspaces\n",
    "res_stream_Q = res_stream @ W_Q @ torch.tensor(W_Q_inv, device=device)\n",
    "res_stream_K = res_stream @ W_K @ torch.tensor(W_K_inv, device=device)  \n",
    "res_stream_V = res_stream @ W_V @ torch.tensor(W_V_inv, device=device)  \n",
    "\n",
    "# Convert projected residual streams back to character space\n",
    "res_stream_Q_letters,_ = from_logits_to_chars(model.lm_head(res_stream_Q),itos)\n",
    "res_stream_K_letters,_ = from_logits_to_chars(model.lm_head(res_stream_K),itos)\n",
    "res_stream_V_letters,_ = from_logits_to_chars(model.lm_head(res_stream_V),itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20591b2f",
   "metadata": {},
   "source": [
    "Executing the cell below will reproduce Figure 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 2\n",
    "\n",
    "@interact(weight_thr=widgets.FloatSlider(min=0.0, max=1.0, step=0.05, value=0.0,continuous_update=False,description=\"Threshold:\"),\n",
    "          target_flows=widgets.Dropdown(options={'All tokens': all_token_indices,\n",
    "                                                 'All output tokens': all_ouptut_token_indices,\n",
    "                                                 'Output premise tokens': output_premise_token_indices,\n",
    "                                                 'Output \\'>\\' tokens': output_greater_token_indices,\n",
    "                                                 'Output consequent tokens': output_consequent_token_indices,\n",
    "                                                 'Output \\',\\' tokens': output_comma_token_indices,\n",
    "                                                 'Output \\'-\\' token': output_minus_token_index\n",
    "                                                 },\n",
    "                                        value=all_token_indices,\n",
    "                                        description='L1->L2 Links:'),\n",
    "          attention_data=widgets.Dropdown(options={'Current prompt': [attention_layer_sources, attention_layer_targets, attention_layer_values],\n",
    "                                                  'Average on all examples': [avg_attention_layer_sources, avg_attention_layer_targets, avg_attention_layer_values],\n",
    "                                                  'Average on positive examples': [pos_avg_attention_layer_sources, pos_avg_attention_layer_targets, pos_avg_attention_layer_values],\n",
    "                                                  'Average on negative examples': [neg_avg_attention_layer_sources, neg_avg_attention_layer_targets, neg_avg_attention_layer_values],\n",
    "                                                  },\n",
    "                                                   value=[attention_layer_sources, attention_layer_targets, attention_layer_values],\n",
    "                                                   description='Attention:'),\n",
    "          show_kqv=widgets.Checkbox(value=False, description='Show K, Q, V', disabled=False))\n",
    "def draw(weight_thr,target_flows, attention_data,show_kqv):\n",
    "   if show_kqv:\n",
    "      res_stream_data=[res_stream_Q_letters,res_stream_K_letters,res_stream_V_letters]\n",
    "   else:\n",
    "      res_stream_data=None\n",
    "\n",
    "   draw_sankey(prompt_last_token_charlist, output_charlist, l1_top_k_subs, attention_data,res_stream_data, all_token_indices, weight_thr, target_flows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c45fa5",
   "metadata": {},
   "source": [
    "Executing the cell below will reproduce Figure 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f52ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 3\n",
    "\n",
    "@interact(weight_thr=widgets.FloatSlider(min=0.0, max=1.0, step=0.05, value=0.4,continuous_update=False,description=\"Threshold:\"),\n",
    "          target_flows=widgets.Dropdown(options={'All tokens': all_token_indices,\n",
    "                                                 'All output tokens': all_ouptut_token_indices,\n",
    "                                                 'Output premise tokens': output_premise_token_indices,\n",
    "                                                 'Output \\'>\\' tokens': output_greater_token_indices,\n",
    "                                                 'Output consequent tokens': output_consequent_token_indices,\n",
    "                                                 'Output \\',\\' tokens': output_comma_token_indices,\n",
    "                                                 'Output \\'-\\' token': output_minus_token_index\n",
    "                                                 },\n",
    "                                        value=output_greater_token_indices,\n",
    "                                        description='L1->L2 Links:'),\n",
    "          attention_data=widgets.Dropdown(options={'Current prompt': [attention_layer_sources, attention_layer_targets, attention_layer_values],\n",
    "                                                  'Average on all examples': [avg_attention_layer_sources, avg_attention_layer_targets, avg_attention_layer_values],\n",
    "                                                  'Average on positive examples': [pos_avg_attention_layer_sources, pos_avg_attention_layer_targets, pos_avg_attention_layer_values],\n",
    "                                                  'Average on negative examples': [neg_avg_attention_layer_sources, neg_avg_attention_layer_targets, neg_avg_attention_layer_values],\n",
    "                                                  },\n",
    "                                                   value=[attention_layer_sources, attention_layer_targets, attention_layer_values],\n",
    "                                                   description='Attention:'),\n",
    "          show_kqv=widgets.Checkbox(value=True, description='Show K, Q, V', disabled=False))\n",
    "def draw(weight_thr,target_flows, attention_data,show_kqv):\n",
    "   if show_kqv:\n",
    "      res_stream_data=[res_stream_Q_letters,res_stream_K_letters,res_stream_V_letters]\n",
    "   else:\n",
    "      res_stream_data=None\n",
    "\n",
    "   draw_sankey(prompt_last_token_charlist, output_charlist, l1_top_k_subs, attention_data,res_stream_data, all_token_indices, weight_thr, target_flows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd526df",
   "metadata": {},
   "source": [
    "Executing the cell below will reproduce Figure 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110617fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 4\n",
    "\n",
    "@interact(weight_thr=widgets.FloatSlider(min=0.0, max=1.0, step=0.05, value=0.4,continuous_update=False,description=\"Threshold:\"),\n",
    "          target_flows=widgets.Dropdown(options={'All tokens': all_token_indices,\n",
    "                                                 'All output tokens': all_ouptut_token_indices,\n",
    "                                                 'Output premise tokens': output_premise_token_indices,\n",
    "                                                 'Output \\'>\\' tokens': output_greater_token_indices,\n",
    "                                                 'Output consequent tokens': output_consequent_token_indices,\n",
    "                                                 'Output \\',\\' tokens': output_comma_token_indices,\n",
    "                                                 'Output -\\' token': output_minus_token_index\n",
    "                                                 },\n",
    "                                        value=output_comma_token_indices,\n",
    "                                        description='L1->L2 Links:'),\n",
    "          attention_data=widgets.Dropdown(options={'Current prompt': [attention_layer_sources, attention_layer_targets, attention_layer_values],\n",
    "                                                  'Average on all examples': [avg_attention_layer_sources, avg_attention_layer_targets, avg_attention_layer_values],\n",
    "                                                  'Average on positive examples': [pos_avg_attention_layer_sources, pos_avg_attention_layer_targets, pos_avg_attention_layer_values],\n",
    "                                                  'Average on negative examples': [neg_avg_attention_layer_sources, neg_avg_attention_layer_targets, neg_avg_attention_layer_values],\n",
    "                                                  },\n",
    "                                                   value=[attention_layer_sources, attention_layer_targets, attention_layer_values],\n",
    "                                                   description='Attention:'),\n",
    "          show_kqv=widgets.Checkbox(value=True, description='Show K, Q, V', disabled=False))\n",
    "def draw(weight_thr,target_flows, attention_data,show_kqv):\n",
    "   if show_kqv:\n",
    "      res_stream_data=[res_stream_Q_letters,res_stream_K_letters,res_stream_V_letters]\n",
    "   else:\n",
    "      res_stream_data=None\n",
    "\n",
    "   draw_sankey(prompt_last_token_charlist, output_charlist, l1_top_k_subs, attention_data,res_stream_data, all_token_indices, weight_thr, target_flows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dbc5ba",
   "metadata": {},
   "source": [
    "Executing the cell below will reproduce Figure 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 5\n",
    "\n",
    "@interact(weight_thr=widgets.FloatSlider(min=0.0, max=1.0, step=0.05, value=0.1,continuous_update=False,description=\"Threshold:\"),\n",
    "          target_flows=widgets.Dropdown(options={'All tokens': all_token_indices,\n",
    "                                                 'All output tokens': all_ouptut_token_indices,\n",
    "                                                 'Output premise tokens': output_premise_token_indices,\n",
    "                                                 'Output \\'>\\' tokens': output_greater_token_indices,\n",
    "                                                 'Output consequent tokens': output_consequent_token_indices,\n",
    "                                                 'Output \\',\\' tokens': output_comma_token_indices,\n",
    "                                                 'Output \\'-\\' token': output_minus_token_index\n",
    "                                                 },\n",
    "                                        value=output_minus_token_index,\n",
    "                                        description='L1->L2 Links:'),\n",
    "          attention_data=widgets.Dropdown(options={'Current prompt': [attention_layer_sources, attention_layer_targets, attention_layer_values],\n",
    "                                                  'Average on all examples': [avg_attention_layer_sources, avg_attention_layer_targets, avg_attention_layer_values],\n",
    "                                                  'Average on positive examples': [pos_avg_attention_layer_sources, pos_avg_attention_layer_targets, pos_avg_attention_layer_values],\n",
    "                                                  'Average on negative examples': [neg_avg_attention_layer_sources, neg_avg_attention_layer_targets, neg_avg_attention_layer_values],\n",
    "                                                  },\n",
    "                                                   value=[pos_avg_attention_layer_sources, pos_avg_attention_layer_targets, pos_avg_attention_layer_values],\n",
    "                                                   description='Attention:'),\n",
    "          show_kqv=widgets.Checkbox(value=False, description='Show K, Q, V', disabled=False))\n",
    "def draw(weight_thr,target_flows, attention_data,show_kqv):\n",
    "   if show_kqv:\n",
    "      res_stream_data=[res_stream_Q_letters,res_stream_K_letters,res_stream_V_letters]\n",
    "   else:\n",
    "      res_stream_data=None\n",
    "\n",
    "   draw_sankey(prompt_last_token_charlist, output_charlist, l1_top_k_subs, attention_data,res_stream_data, all_token_indices, weight_thr, target_flows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tr_lens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
